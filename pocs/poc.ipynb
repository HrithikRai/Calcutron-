{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Goal** - To create a LLM based system that answers calculus related questions in an easy intuitive way\n",
    "#### Targets - \n",
    "1. Input question via text or image (do not entertain off-topic questions)\n",
    "2. Setup pipelines - Data Collection pipeline, Feature Pipeline (Advanced RAG), Inference Pipeline \n",
    "3. Orchestrate pipelines via ZenML\n",
    "4. Create Agentic workflows\n",
    "5. Create routing mechanisms\n",
    "6. Create routing mechanisms\n",
    "7. Deploy as restAPI via FastAPI\n",
    "8. Design user interface - Streamlit/ Gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG resource - \n",
    "1. Calculus Made Easy by  F. R. S. 1910 (https://www.gutenberg.org/files/33283/33283-pdf.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Agentic Approach for Conversational Context - \n",
    "1. User question → Embed question → Search vector DB/graph → Retrieve passages → Generate explanation via LLM.\n",
    "2. Semantic Re-ranking: After retrieving passages, use a re-ranking model to prioritize relevance.(BM25,BERT)\n",
    "3. Fine-tune the LLM on examples from Calculus Made Easy\n",
    "4. Highlight \"intuitive\" aspects using additional prompts or examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train LLM Locally\n",
    "1. LLM Studio\n",
    "2. Jan\n",
    "3. LlamaFile\n",
    "4. GPT4ALL\n",
    "5. Ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "langchain_env"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
